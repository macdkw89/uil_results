{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define column headers for csv export\n",
    "columns_21 = ['Event', 'School', 'TEA', 'City', 'Directors', 'Conference', 'Classification', 'Year', 'ID', \n",
    "    'Stage Judge 1', 'Stage Judge 2', 'Stage Judge 3', 'Stage Final', \n",
    "    'SR Judge 1', 'SR Judge 2', 'SR Judge 3', 'SR Final', 'Award', \n",
    "    'Selection 1', 'Selection 2', 'Selection 3', 'Date', 'Region', 'cj1', 'cj2', 'cj3', 'srj1', 'srj2', 'srj3']\n",
    "columns_22 = ['Event', 'School', 'TEA', 'City', 'Directors', 'Conference', 'Classification', 'Year', 'ID', \n",
    "    'Stage Judge 1', 'Stage Judge 2', 'Stage Judge 3', 'Stage Final', \n",
    "    'SR Judge 1', 'SR Judge 2', 'SR Judge 3', 'SR Final', 'Award', \n",
    "    'Selection 1', 'Selection 2', 'Selection 3', 'Date', 'Region', 'cj1', 'cj2', 'cj3', 'srj1', 'srj2', 'srj3', 'oops']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group the CSVs together, and fix rows with Accompanist error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of merged files returned\n",
    "files = glob.glob(\"full_run/*.csv\")\n",
    "\n",
    "# joining files with concat and read_csv\n",
    "df = pd.concat(map(pd.read_csv, files), ignore_index=True)\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "# drop unnamed column\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "# name the columns\n",
    "df.columns = columns_22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event</th>\n",
       "      <th>School</th>\n",
       "      <th>TEA</th>\n",
       "      <th>City</th>\n",
       "      <th>Directors</th>\n",
       "      <th>Conference</th>\n",
       "      <th>Classification</th>\n",
       "      <th>Year</th>\n",
       "      <th>ID</th>\n",
       "      <th>Stage Judge 1</th>\n",
       "      <th>...</th>\n",
       "      <th>Selection 2</th>\n",
       "      <th>Selection 3</th>\n",
       "      <th>Date</th>\n",
       "      <th>Region</th>\n",
       "      <th>cj1</th>\n",
       "      <th>cj2</th>\n",
       "      <th>cj3</th>\n",
       "      <th>srj1</th>\n",
       "      <th>srj2</th>\n",
       "      <th>srj3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>60803</td>\n",
       "      <td>60803</td>\n",
       "      <td>60803</td>\n",
       "      <td>60803</td>\n",
       "      <td>60803</td>\n",
       "      <td>60803</td>\n",
       "      <td>60803</td>\n",
       "      <td>60803</td>\n",
       "      <td>60803</td>\n",
       "      <td>60803</td>\n",
       "      <td>...</td>\n",
       "      <td>60803</td>\n",
       "      <td>60803</td>\n",
       "      <td>60803</td>\n",
       "      <td>60803</td>\n",
       "      <td>60803</td>\n",
       "      <td>60803</td>\n",
       "      <td>60803</td>\n",
       "      <td>60803</td>\n",
       "      <td>60803</td>\n",
       "      <td>60625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1</td>\n",
       "      <td>6236</td>\n",
       "      <td>2373</td>\n",
       "      <td>1498</td>\n",
       "      <td>24456</td>\n",
       "      <td>28</td>\n",
       "      <td>39</td>\n",
       "      <td>210</td>\n",
       "      <td>60631</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>8975</td>\n",
       "      <td>11894</td>\n",
       "      <td>499</td>\n",
       "      <td>155</td>\n",
       "      <td>1116</td>\n",
       "      <td>1219</td>\n",
       "      <td>1196</td>\n",
       "      <td>1230</td>\n",
       "      <td>1344</td>\n",
       "      <td>1203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>100-Concert Band</td>\n",
       "      <td>Allen High School</td>\n",
       "      <td>TEA:</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>Joe Martinez</td>\n",
       "      <td>CC</td>\n",
       "      <td>Varsity</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Colliding Visions  (Balmages/ )</td>\n",
       "      <td>Moscow, 1941  (Balmages)</td>\n",
       "      <td>DATE of EVENT 04/17/2018</td>\n",
       "      <td>Region: 8</td>\n",
       "      <td>1. Keith Bearden</td>\n",
       "      <td>2. Cindy Lansford</td>\n",
       "      <td>3. Randy Vaughn</td>\n",
       "      <td>1. Phil Anthony</td>\n",
       "      <td>2. Tye Ann Payne</td>\n",
       "      <td>3. Rick Yancey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>60803</td>\n",
       "      <td>112</td>\n",
       "      <td>56877</td>\n",
       "      <td>2882</td>\n",
       "      <td>29</td>\n",
       "      <td>14895</td>\n",
       "      <td>31202</td>\n",
       "      <td>3274</td>\n",
       "      <td>78</td>\n",
       "      <td>25874</td>\n",
       "      <td>...</td>\n",
       "      <td>422</td>\n",
       "      <td>446</td>\n",
       "      <td>714</td>\n",
       "      <td>3135</td>\n",
       "      <td>709</td>\n",
       "      <td>463</td>\n",
       "      <td>843</td>\n",
       "      <td>448</td>\n",
       "      <td>341</td>\n",
       "      <td>736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Event              School    TEA          City  \\\n",
       "count               60803               60803  60803         60803   \n",
       "unique                  1                6236   2373          1498   \n",
       "top      100-Concert Band   Allen High School   TEA:   San Antonio   \n",
       "freq                60803                 112  56877          2882   \n",
       "\n",
       "            Directors Conference Classification   Year     ID  Stage Judge 1  \\\n",
       "count           60803      60803          60803  60803  60803          60803   \n",
       "unique          24456         28             39    210  60631             13   \n",
       "top      Joe Martinez         CC       Varsity    2019      1              1   \n",
       "freq               29      14895          31202   3274     78          25874   \n",
       "\n",
       "        ...                       Selection 2                Selection 3  \\\n",
       "count   ...                             60803                      60803   \n",
       "unique  ...                              8975                      11894   \n",
       "top     ...   Colliding Visions  (Balmages/ )   Moscow, 1941  (Balmages)   \n",
       "freq    ...                               422                        446   \n",
       "\n",
       "                             Date     Region               cj1  \\\n",
       "count                       60803      60803             60803   \n",
       "unique                        499        155              1116   \n",
       "top     DATE of EVENT 04/17/2018   Region: 8  1. Keith Bearden   \n",
       "freq                          714       3135               709   \n",
       "\n",
       "                      cj2              cj3             srj1              srj2  \\\n",
       "count               60803            60803            60803             60803   \n",
       "unique               1219             1196             1230              1344   \n",
       "top     2. Cindy Lansford  3. Randy Vaughn  1. Phil Anthony  2. Tye Ann Payne   \n",
       "freq                  463              843              448               341   \n",
       "\n",
       "                  srj3  \n",
       "count            60625  \n",
       "unique            1203  \n",
       "top     3. Rick Yancey  \n",
       "freq               736  \n",
       "\n",
       "[4 rows x 29 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select rows with acc column \n",
    "oops_df = df[df['oops'].notnull()]\n",
    "\n",
    "# delete the acc columns and fix column names\n",
    "oops_fix_df = oops_df.drop(columns=['Conference'])\n",
    "oops_fix_df.columns = columns_21\n",
    "\n",
    "# drop acc rows from df\n",
    "df = df.loc[df['oops'].isnull() == True]\n",
    "\n",
    "# add fixed df to df\n",
    "df = pd.concat([df, oops_fix_df], ignore_index=True)\n",
    "\n",
    "# drop oops column\n",
    "df.drop(columns=['oops'], inplace=True)\n",
    "\n",
    "# drop rows where Event contains '9'\n",
    "df = df[df['Event'].str.contains('9') == False]\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60803"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select rows where selection 3 is null\n",
    "df_clean = df\n",
    "df_clean = df_clean[df_clean['Selection 3'].isnull() == False]\n",
    "len(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim whitespace, double spaces, commas, and periods from selections\n",
    "selection_columns = ['Selection 1', 'Selection 2', 'Selection 3']\n",
    "\n",
    "for i in selection_columns:\n",
    "    df_clean[i] = df_clean[i].str.strip()\n",
    "    df_clean[i] = df_clean[i].str.replace('  ', ' ', regex=False)\n",
    "    df_clean[i] = df_clean[i].str.replace(',', '', regex=False)\n",
    "    df_clean[i] = df_clean[i].str.replace('.', '', regex=False)\n",
    "\n",
    "# Trim whitespace from classification column\n",
    "df_clean['Classification'] = df_clean['Classification'].str.strip()\n",
    "\n",
    "# Remove composer/arranger information from selections\n",
    "for column in selection_columns:\n",
    "    # remove all inside parenthesis\n",
    "    df_clean[column] = df_clean[column].str.replace('\\(.*\\)', '', regex=True)\n",
    "    # trim whitespace\n",
    "    df_clean[column] = df_clean[column].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows where conference contains 'Acc'\n",
    "df_clean = df_clean[df_clean['Conference'].str.contains('Acc') == False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix names of some conferences\n",
    "df_clean['Conference'] = df_clean['Conference'].replace('2C', 'CC')\n",
    "df_clean['Conference'] = df_clean['Conference'].replace('4A', 'AAAA')\n",
    "df_clean['Conference'] = df_clean['Conference'].replace('cc', 'CC')\n",
    "df_clean['Conference'] = df_clean['Conference'].replace('1C', 'C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make df_clean column integers\n",
    "df_clean['Year'] = df_clean['Year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Varsity ' 'CC' 'AAA' 'C' 'CCC' 'AAAA' 'AA' 'A' 'AAAAA' 'Non-Varsity '\n",
      " 'Sub Non-Varsity ' 'Sub Non-Varsity B' 'BBB' 'Non-Varsity A' 'BB' 'B'\n",
      " 'Var-Composite ' ' ' 'Non-Varsity C' 'NVar-Composite ' 'Var-Combined '\n",
      " 'AAAAAA']\n",
      "['2005' 'Varsity' 'Non-Varsity' 'Non-Varsity A' 'Non-Varsity B' 'Combined'\n",
      " 'Sub Non-Varsity' 'Sub Non-Varsity C' 'Sub Non-Varsity B'\n",
      " 'Sub Non-Varsity A' 'Non-Varsity C' 'Non-Varsity F' 'Sub Non-Varsity D'\n",
      " 'Sub Non-Varsity E' 'Non-Varsity E' '2006' 'Non-Varsity D' '2008'\n",
      " 'Var-Combined' 'Var-Composite' '' '2009' 'NVar-Composite' '2010' '2011'\n",
      " '2012' 'NVar-Combined' '2013' 'Sub Non-Varsity F' '2014' 'Varsity A'\n",
      " 'Varsity C' 'Varsity B' '2015' 'Sub Non-Varsity G' 'Var-Composite A'\n",
      " 'Sub Non-Varsity H' 'Sub Non-Varsity I' 'NVar-Composite A']\n",
      "[ 17246   2005  14077  11197  11109  17900  16404  17069  17328  13344\n",
      "  15094  13014  17315  17648  18475  18405  17673  14770  13205  13902\n",
      "  15470  15934  13485  16213  15350  15679  15324  15314  15307  15306\n",
      "  15299  15286  15285  15659  13687  14327  12811  12205   2006  11014\n",
      "   2007   2008  35160   2009  47560  45191  45104  45182  46485  44292\n",
      "  50328  47999  48920  50759  44294  48170  46386  49872  50493  48661\n",
      "  49145  46108  50260   2010  56078  56241  54936  53910  52795  54505\n",
      "  53020  55434  56728  53211  53302  58047  58342  57702  56477  53145\n",
      "  58874  58840  59065  59378  53787  55213  54701  58418  58747  58606\n",
      "  57719  59132  59178  58033  59340  58344  61095   2011  62049  66236\n",
      "  64268  64262  63170  65547  67406  66910  65191  66015  62734  59940\n",
      "  65738  65174  60625  66830  61502  66992  67830  63744  65785  59905\n",
      "  68247  62267  63683  62437  62047  67275  64462  63858  67595  64219\n",
      "  67662   2012  68890  71856  74197  76620  71735  71456  71285  71124\n",
      "  71009  70932  69702  68769  69385  70987  69750  73839  76805  68896\n",
      "  70327  75301  75363  75360  72065  75163  73474  72383  75952  75552\n",
      "  74594  74464  76594  72848  73458   2013  84757  85265  81523  85468\n",
      "  77561  81653  86165  86440  80464  86288  84039  77679   2014  92973\n",
      "  95724  91945  86994  88369  87217  92418  92415   2015 104122   2016\n",
      "   2017   2018   2019   2020   2021   2022]\n"
     ]
    }
   ],
   "source": [
    "print(df_clean['Conference'].unique())\n",
    "print(df_clean['Classification'].unique())\n",
    "print(df_clean['Year'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "judging_columns = ['Stage Judge 1', 'Stage Judge 2', 'Stage Judge 3', 'Stage Final', 'SR Judge 1', \n",
    "                'SR Judge 2', 'SR Judge 3', 'SR Final']\n",
    "numbers = ['1', '2', '3', '4', '5']\n",
    "\n",
    "for n in numbers:\n",
    "    for j in judging_columns:\n",
    "        df_clean.loc[df_clean[j] == n, j] = int(n)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ' 2 1 3 4 'DNA' 5 'DQ']\n",
      "[' ' 2 1 4 3 'DNA' 5 'DQ']\n",
      "[' ' 2 3 1 4 'DNA' 'DQ' 5]\n",
      "[' ' 2 1 3 4 'DNA' 5 'DQ']\n",
      "[' ' 1 2 3 4 5 'DNA' 'DQ']\n",
      "[' ' 1 2 3 4 'DNA' 5 'DQ']\n",
      "[' ' 1 2 3 4 'DNA' 5 'DQ']\n",
      "[' ' 1 2 3 4 'DNA' 5 'TD' 'TRC' 'C' 'DQ' 'PLQ' 'TRO' 'RM1' 'RMD' 'RM2'\n",
      " 'RMC' 'A' '-' 11 'SWA' 'NAN' 'B' 'D' 0]\n"
     ]
    }
   ],
   "source": [
    "for j in judging_columns:\n",
    "    print(df_clean[j].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim whitespace, double spaces, commas, and periods from selections\n",
    "selection_columns = ['Selection 1', 'Selection 2', 'Selection 3']\n",
    "\n",
    "for i in selection_columns:\n",
    "    df_clean[i] = df_clean[i].str.strip()\n",
    "    df_clean[i] = df_clean[i].str.replace('  ', ' ', regex=False)\n",
    "    df_clean[i] = df_clean[i].str.replace(',', '', regex=False)\n",
    "    df_clean[i] = df_clean[i].str.replace('.', '', regex=False)\n",
    "\n",
    "# Trim whitespace from classification column\n",
    "df_clean['Classification'] = df_clean['Classification'].str.strip()\n",
    "\n",
    "# Remove composer/arranger information from selections\n",
    "for column in selection_columns:\n",
    "    # remove all inside parenthesis\n",
    "    df_clean[column] = df_clean[column].str.replace('\\(.*\\)', '', regex=True)\n",
    "    # trim whitespace\n",
    "    df_clean[column] = df_clean[column].str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.columns = df_clean.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60803\n"
     ]
    }
   ],
   "source": [
    "# Drop Event and TEA column\n",
    "df = df.drop(columns=['Event', 'TEA'])\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60269\n"
     ]
    }
   ],
   "source": [
    "# Remove DNA, DQ\n",
    "for i in judging_columns:\n",
    "    df_clean = df_clean[df_clean[i] != 'DNA']\n",
    "    df_clean = df_clean[df_clean[i] != 'DQ']\n",
    "\n",
    "# Convert blanks to nans\n",
    "for i in judging_columns:\n",
    "    df_clean[i] = df_clean[i].replace(['', ' '], np.nan)\n",
    "\n",
    "print(len(df_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average together Stage Judge 1, 2, and 3 into a new column\n",
    "\n",
    "df_clean['Stage Average'] = (df_clean['Stage Judge 1'] + df_clean['Stage Judge 2'] + df_clean['Stage Judge 3']) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort df_clean by year\n",
    "df_clean.sort_values(by=['Year'], inplace=True)\n",
    "\n",
    "# drop Event column\n",
    "df_clean = df_clean.drop(columns=['Event'])\n",
    "\n",
    "# drop TEA column\n",
    "df_clean = df_clean.drop(columns=['TEA'])\n",
    "\n",
    "# drop ID column\n",
    "df_clean = df_clean.drop(columns=['ID'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all of the pml csv files into a dataframe\n",
    "files = glob.glob(\"csv_files/pml/*.csv\")\n",
    "pml_df = pd.concat([pd.read_csv(f) for f in files], ignore_index=True)\n",
    "# convert pml_df to csv\n",
    "pml_df.to_csv(\"csv_files/pml_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['Date'] = df_clean['Date'].str.replace('DATE of EVENT ', '')\n",
    "judge_name_columns = ['cj1', 'cj2', 'cj3', 'srj1', 'srj2', 'srj3']\n",
    "for i in judge_name_columns:\n",
    "    df_clean[i] = df_clean[i].str.replace('1. ', '', regex=False)\n",
    "    df_clean[i] = df_clean[i].str.replace('2. ', '', regex=False)\n",
    "    df_clean[i] = df_clean[i].str.replace('3. ', '', regex=False)\n",
    "    # all lowercase\n",
    "    df_clean[i] = df_clean[i].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each judge name column, remove everything after the first comma\n",
    "for i in judge_name_columns:\n",
    "    #df_clean[i] = df_clean[i].str.split(',', expand=True)[0]\n",
    "    #df_clean[i] = df_clean[i].str.split('-', expand=True)[0]\n",
    "    # trim whitespace\n",
    "    df_clean[i] = df_clean[i].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = df_clean.columns\n",
    "# trim whitespace from all columns\n",
    "for i in all_columns:\n",
    "    try:\n",
    "        df_clean[i] = df_clean[i].str.strip()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows where School = 0\n",
    "df_clean = df_clean[df_clean['School'] != '0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rows where year is greater than 3000\n",
    "df_clean_yr_error = df_clean[df_clean['Year'] > 3000]\n",
    "\n",
    "# drop rows where year is greater than 3000\n",
    "df_clean = df_clean[df_clean['Year'] < 3000]\n",
    "\n",
    "df_clean_yr_error['Year'] = df_clean_yr_error['Classification']\n",
    "df_clean_yr_error['Classification'] = df_clean_yr_error['Conference']\n",
    "\n",
    "# fill conference column with blanks\n",
    "df_clean_yr_error['Conference'] = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine df_clean and df_clean_yr_error\n",
    "df_clean = pd.concat([df_clean, df_clean_yr_error], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AAAAA' 'A' 'AA' 'AAA' 'AAAA' 'C' 'CC' 'CCC' 'BBB' 'BB' 'B' 'AAAAAA' '']\n",
      "['Non-Varsity' 'Varsity' 'Sub Non-Varsity' 'Non-Varsity A'\n",
      " 'Sub Non-Varsity B' 'Sub Non-Varsity A' 'Sub Non-Varsity C'\n",
      " 'Sub Non-Varsity E' 'Sub Non-Varsity D' 'Non-Varsity B' 'Non-Varsity E'\n",
      " 'Non-Varsity C' 'Combined' 'Non-Varsity F' 'Non-Varsity D'\n",
      " 'Var-Composite' 'Var-Combined' '' 'NVar-Composite' 'NVar-Combined'\n",
      " 'Sub Non-Varsity F' 'Varsity C' 'Varsity B' 'Varsity A'\n",
      " 'Sub Non-Varsity G' 'Var-Composite A' 'Sub Non-Varsity H'\n",
      " 'Sub Non-Varsity I' 'NVar-Composite A']\n",
      "[2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018\n",
      " 2019 2020 2021 2022 '2008' '2009' '2010' '2011' '2012' '2013' '2014'\n",
      " '2015']\n"
     ]
    }
   ],
   "source": [
    "print(df_clean['Conference'].unique())\n",
    "print(df_clean['Classification'].unique())\n",
    "print(df_clean['Year'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to csv\n",
    "df_clean.to_csv(\"csv_files/full_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "53babf5c189ad8a4933a2bd5063a1840a2c47c9b82a6c06a0d6cefa0137ac8c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
